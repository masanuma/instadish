import streamlit as st
from PIL import Image, ImageEnhance, ImageDraw
import io
import numpy as np
import cv2
import random
import torch
import clip

st.set_page_config(page_title="InstaDish | é£²é£Ÿåº—ã‚¤ãƒ³ã‚¹ã‚¿ç”»åƒã‚¢ãƒ—ãƒª", layout="centered")
st.title("InstaDish ğŸ½ï¸ | é£²é£Ÿåº—å‘ã‘Instagramç”»åƒåŠ å·¥ï¼‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ææ¡ˆ")
st.caption("by Masashi")

st.header("1. å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰")
uploaded_files = st.file_uploader("æ–™ç†ãƒ»ãƒ‰ãƒªãƒ³ã‚¯ãªã©ã®å†™çœŸã‚’é¸ã‚“ã§ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠOKï¼‰", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

st.header("2. æ¥­æ…‹ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã‚’é¸æŠ")
business_type = st.selectbox("æ¥­æ…‹ã‚’é¸ã‚“ã§ãã ã•ã„", ["å’Œé£Ÿ", "æ´‹é£Ÿ", "ä¸­è¯", "å±…é…’å±‹", "ãƒãƒ¼", "ã‚¨ã‚¹ãƒ‹ãƒƒã‚¯", "ã‚«ãƒ•ã‚§"])
target_audience = st.selectbox("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã‚’é¸ã‚“ã§ãã ã•ã„", ["ã‚¤ãƒ³ã‚¹ã‚¿å¥½ã", "å¤–å›½äººè¦³å…‰å®¢", "ä¼šç¤¾å“¡", "ã‚·ãƒ‹ã‚¢", "OL"])

with st.expander("ğŸ“· æ’®å½±ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¦‹ã‚‹"):
    st.markdown("""
    ### ğŸ“¸ ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãŠã™ã™ã‚æ’®å½±ãƒã‚¤ãƒ³ãƒˆ
    - **ãƒ‰ãƒªãƒ³ã‚¯**ï¼šã‚°ãƒ©ã‚¹ã®é«˜ã•ã‚’æ´»ã‹ã—ã¦æ–œã‚ä¸‹ã‹ã‚‰
    - **ã‚«ãƒ•ã‚§ãƒ¡ãƒ‹ãƒ¥ãƒ¼**ï¼šçœŸä¸Šã‹ã‚‰å…¨ä½“ã‚’ãã‚Œã„ã«
    - **ãƒãƒ¼ã®é›°å›²æ°—**ï¼šãƒ©ãƒ™ãƒ«ã‚„ç…§æ˜ã‚’æ´»ã‹ã—ãŸãƒ­ãƒ¼ã‚¢ãƒ³ã‚°ãƒ«
    - **è¤‡æ•°çš¿ã®æ–™ç†**ï¼šå¥¥è¡Œãã‚’å‡ºã™ã‚ˆã†ã«45åº¦ã§
    - **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚„ãƒ©ãƒ™ãƒ«ãŒé‡è¦ãªå ´åˆ**ï¼šä¸­å¤®é…ç½®ï¼‹æ˜ã‚‹ã•é‡è¦–
    """)

def generate_hashtags(business, audience):
    tags = ["#InstaFood", "#ã‚°ãƒ«ãƒ¡", "#é£Ÿã¹ã‚¹ã‚¿ã‚°ãƒ©ãƒ ", "#ãŠã—ã‚ƒã‚Œã”ã¯ã‚“"]
    if business == "ã‚«ãƒ•ã‚§": tags += ["#ã‚«ãƒ•ã‚§å·¡ã‚Š", "#CafeTime", "#ã‚³ãƒ¼ãƒ’ãƒ¼å¥½ã"]
    if business == "å±…é…’å±‹": tags += ["#å±…é…’å±‹ãƒ¡ã‚·", "#æ—¥æœ¬é…’å¥½ã", "#å¤§è¡†é…’å ´"]
    if business == "ãƒãƒ¼": tags += ["#BarTime", "#ã‚¯ãƒ©ãƒ•ãƒˆã‚¸ãƒ³", "#éš ã‚Œå®¶ãƒãƒ¼"]
    if business == "ã‚¨ã‚¹ãƒ‹ãƒƒã‚¯": tags += ["#ã‚¨ã‚¹ãƒ‹ãƒƒã‚¯æ–™ç†", "#SpicyLovers", "#ã‚¢ã‚¸ã‚¢ã”ã¯ã‚“"]
    if business == "å’Œé£Ÿ": tags += ["#å’Œé£Ÿ", "#JapaneseCuisine", "#ç¾å‘³ã—ã„å’Œé£Ÿ"]
    if business == "æ´‹é£Ÿ": tags += ["#æ´‹é£Ÿãƒ©ãƒ³ãƒ", "#WesternFood", "#ãŠã—ã‚ƒã‚Œãƒ‡ã‚£ãƒŠãƒ¼"]
    if business == "ä¸­è¯": tags += ["#ä¸­è¯æ–™ç†", "#DimSum", "#æœ¬æ ¼ä¸­è¯"]
    if audience == "ã‚¤ãƒ³ã‚¹ã‚¿å¥½ã": tags += ["#æ˜ ãˆã‚°ãƒ«ãƒ¡", "#ãƒ•ã‚©ãƒˆã‚¸ã‚§ãƒ‹ãƒƒã‚¯", "#SNSæ˜ ãˆ"]
    if audience == "å¤–å›½äººè¦³å…‰å®¢": tags += ["#VisitJapan", "#TokyoFoodie", "#JapaneseCulture"]
    if audience == "ä¼šç¤¾å“¡": tags += ["#ãƒ©ãƒ³ãƒã‚¿ã‚¤ãƒ ", "#ãŠç–²ã‚Œæ§˜ã§ã™", "#ä»•äº‹å¸°ã‚Šã‚°ãƒ«ãƒ¡"]
    if audience == "ã‚·ãƒ‹ã‚¢": tags += ["#è½ã¡ç€ã„ãŸæ™‚é–“", "#å¤§äººã®é£Ÿäº‹", "#ã‚†ã£ãã‚Šã”ã¯ã‚“"]
    if audience == "OL": tags += ["#å¥³å­ä¼šã”ã¯ã‚“", "#OLãƒ©ãƒ³ãƒ", "#æ˜¼ä¼‘ã¿ã‚«ãƒ•ã‚§"]
    return sorted(set(tags))[:20]

@st.cache_resource
def load_clip_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess, device

def classify_image_clip(image):
    model, preprocess, device = load_clip_model()
    class_names = [
        "cocktail", "sushi", "ramen", "cake", "steak", "pizza", "bar counter", "candlelight", "bottle", "coffee"
    ]
    inputs = torch.cat([clip.tokenize(f"a photo of {c}") for c in class_names]).to(device)
    image_input = preprocess(image).unsqueeze(0).to(device)
    with torch.no_grad():
        image_features = model.encode_image(image_input)
        text_features = model.encode_text(inputs)
        logits_per_image, _ = model(image_input, inputs)
        probs = logits_per_image.softmax(dim=-1).cpu().numpy()
    return class_names[np.argmax(probs)], max(probs[0])

def generate_caption(label, confidence):
    phrases = {
        "cocktail": "å¤œã®æ™‚é–“ã«ã´ã£ãŸã‚Šãªä¸€æ¯ã‚’ã€‚",
        "sushi": "ä¸€è²«ä¸€è²«ã«å¿ƒã‚’è¾¼ã‚ã¦ã€‚",
        "ramen": "ã‚¹ãƒ¼ãƒ—ã¾ã§é£²ã¿å¹²ã—ãŸããªã‚‹ç¾å‘³ã—ã•ã€‚",
        "cake": "ç”˜ã„æ™‚é–“ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ã€‚",
        "steak": "ã‚¸ãƒ¥ãƒ¼ã‚·ãƒ¼ã§ãƒœãƒªãƒ¥ãƒ¼ãƒ ãŸã£ã·ã‚Šã€‚",
        "pizza": "ãƒãƒ¼ã‚ºãŸã£ã·ã‚Šã§ã‚¢ãƒ„ã‚¢ãƒ„ã€‚",
        "bar counter": "é™ã‹ãªå¤œã«ã—ã£ã¨ã‚Šã¨ã€‚",
        "candlelight": "ç¯ã‚Šã«åŒ…ã¾ã‚ŒãŸç™’ã—ã®ç©ºé–“ã€‚",
        "bottle": "ã“ã ã‚ã‚Šã®ãƒœãƒˆãƒ«ãŒãšã‚‰ã‚Šã€‚",
        "coffee": "åˆå¾Œã®ä¼‘æ¯ã«ã€ã»ã£ã¨ã²ã¨æ¯ã€‚"
    }
    if confidence < 0.3:
        return "é›°å›²æ°—ã‚’å¤§åˆ‡ã«ã—ãŸä¸€æšã§ã™ã€‚ãœã²ãƒã‚§ãƒƒã‚¯ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
    return phrases.get(label, "ãŠã™ã™ã‚ã®ä¸€å“ã§ã™ã€‚ãœã²ã”è³å‘³ãã ã•ã„ï¼")

def process_image(image):
    enhancer_brightness = ImageEnhance.Brightness(image)
    bright_image = enhancer_brightness.enhance(1.2)
    enhancer_contrast = ImageEnhance.Contrast(bright_image)
    contrast_image = enhancer_contrast.enhance(1.3)
    enhancer_sharpness = ImageEnhance.Sharpness(contrast_image)
    sharp_image = enhancer_sharpness.enhance(2.0)
    r, g, b = sharp_image.split()
    r = r.point(lambda i: min(255, int(i * 1.1)))
    g = g.point(lambda i: min(255, int(i * 1.05)))
    b = b.point(lambda i: int(i * 0.9))
    return Image.merge("RGB", (r, g, b))

def check_composition(pil_image):
    np_image = np.array(pil_image)
    gray = cv2.cvtColor(np_image, cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(gray, 100, 200)
    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    height, width = gray.shape
    center_x, center_y = width // 2, height // 2
    label = "âœ… æ§‹å›³ãƒã‚§ãƒƒã‚¯çµæœï¼š"
    if len(contours) == 0:
        return label + "è¢«å†™ä½“ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆç”»åƒãŒæš—ã„/ã¼ã‚„ã‘ã¦ã„ã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰"
    largest = max(contours, key=cv2.contourArea)
    M = cv2.moments(largest)
    if M["m00"] == 0:
        return label + "è¢«å†™ä½“ã®ä¸­å¿ƒã‚’ç‰¹å®šã§ãã¾ã›ã‚“"
    cx, cy = int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"])
    offset_x = abs(cx - center_x) / width
    offset_y = abs(cy - center_y) / height
    feedback = []
    if offset_x < 0.1 and offset_y < 0.1:
        feedback.append("ä¸­å¿ƒé…ç½®OK")
    else:
        feedback.append("æ§‹å›³ã‚’ä¸­å¿ƒã«è¿‘ã¥ã‘ã‚‹ã¨ã‚ˆã‚Šè‰¯ã„ã§ã™")
    if width / height > 1.2:
        feedback.append("æ¨ªé•·æ§‹å›³ã€‚ä½™ç™½ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†")
    else:
        feedback.append("ç¸¦æ§‹å›³ã¾ãŸã¯æ­£æ–¹å½¢ã€‚SNSå‘ãã§ã™")
    return label + " / ".join(feedback)

def generate_crop_preview(pil_image):
    width, height = pil_image.size
    center_x, center_y = width // 2, height // 2
    crop_size = min(width, height)
    box_1to1 = (center_x - crop_size//2, center_y - crop_size//2, center_x + crop_size//2, center_y + crop_size//2)
    box_4to5 = (center_x - crop_size//2, center_y - int(crop_size*0.4), center_x + crop_size//2, center_y + int(crop_size*0.6))
    crop_1to1 = pil_image.crop(box_1to1)
    crop_4to5 = pil_image.crop(box_4to5)
    return crop_1to1, crop_4to5

if uploaded_files:
    if st.button("ğŸ“¸ ç”»åƒã‚’åŠ å·¥ã—ã¦ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ææ¡ˆ"):
        for uploaded_file in uploaded_files:
            image = Image.open(uploaded_file).convert("RGB")
            st.image(image, caption=f"å…ƒã®ç”»åƒ: {uploaded_file.name}", use_container_width=True)

            st.markdown(check_composition(image))

            crop1, crop2 = generate_crop_preview(image)
            st.image(crop1, caption="ãƒˆãƒªãƒŸãƒ³ã‚°å€™è£œï¼ˆ1:1ï¼‰", use_container_width=True)
            st.image(crop2, caption="ãƒˆãƒªãƒŸãƒ³ã‚°å€™è£œï¼ˆ4:5ï¼‰", use_container_width=True)

            processed = process_image(image)
            st.image(processed, caption="åŠ å·¥æ¸ˆã¿ç”»åƒ", use_container_width=True)

            label, conf = classify_image_clip(image)
            caption = generate_caption(label, conf)
            st.subheader("ğŸ“ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³å€™è£œ")
            st.markdown(f"{caption}ï¼ˆæ¨å®šã‚«ãƒ†ã‚´ãƒª: {label}, ä¿¡é ¼åº¦: {conf:.2f}ï¼‰")

            hashtags = generate_hashtags(business_type, target_audience)
            st.subheader("ğŸ“Œ ãŠã™ã™ã‚ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°")
            st.code(" ".join(hashtags), language="markdown")

            img_bytes = io.BytesIO()
            processed.save(img_bytes, format="JPEG")
            st.download_button(
                label=f"ğŸ“¥ åŠ å·¥ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ{uploaded_file.name}ï¼‰",
                data=img_bytes.getvalue(),
                file_name=f"instadish_{uploaded_file.name}",
                mime="image/jpeg"
            )
else:
    st.info("ä¸Šã®ãƒ•ã‚©ãƒ¼ãƒ ã«ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
